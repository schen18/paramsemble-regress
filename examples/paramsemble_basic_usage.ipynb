{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Paramsemble (Parametric Ensemble Regression) - Basic Usage Guide",
        "",
        "This notebook demonstrates the core functionality of the Paramsemble package, including:",
        "- Training ensemble models with ElasticNet and MARS methods",
        "- Model serialization and loading",
        "- Scoring new data with saved models",
        "- SQL export for database deployment",
        "- Performance visualization and comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Data Generation\n",
        "\n",
        "First, let's import the necessary libraries and generate synthetic data for demonstration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np",
        "import pandas as pd",
        "import matplotlib.pyplot as plt",
        "import seaborn as sns",
        "from sklearn.datasets import make_regression",
        "from sklearn.model_selection import train_test_split",
        "from paramsemble import ParamsembleRegressor",
        "",
        "# Set random seed for reproducibility",
        "np.random.seed(42)",
        "",
        "# Set plotting style",
        "sns.set_style('whitegrid')",
        "plt.rcParams['figure.figsize'] = (12, 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate synthetic regression data\n",
        "X, y = make_regression(\n",
        "    n_samples=1000,\n",
        "    n_features=15,\n",
        "    n_informative=10,\n",
        "    noise=10.0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Create feature names\n",
        "feature_names = [f'feature_{i}' for i in range(X.shape[1])]\n",
        "\n",
        "# Convert to DataFrame\n",
        "X_df = pd.DataFrame(X, columns=feature_names)\n",
        "y_series = pd.Series(y, name='target')\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_df, y_series, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
        "print(f\"Test set size: {X_test.shape[0]} samples\")\n",
        "print(f\"Number of features: {X_train.shape[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 1: ElasticNet Ensemble Method",
        "",
        "Let's train an Paramsemble model using the ElasticNet ensemble method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize Paramsemble with ElasticNet ensembleregressor_elastic = ParamsembleRegressor(    m=50,                    # Generate 50 feature combinations    f=5,                     # Each combination has 5 features    sample='unique',         # No duplicate features in combinations    method='elastic',        # Use ElasticNet for ensemble    spread=10,               # Select top 10 models for ensemble    ELM2json='models/constituent_models_elastic.json',    modeljson='models/ensemble_model_elastic.json',    random_state=42)print(\"Training Paramsemble with ElasticNet ensemble...\")regressor_elastic.fit(X_train, y_train, X_test, y_test)print(\"Training complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View baseline metrics",
        "print(\"\\n=== Baseline Model Performance ===\")",
        "print(f\"Baseline wMAPE: {regressor_elastic.baseline_metrics_['wmape']:.4f}\")",
        "print(f\"Baseline R²: {regressor_elastic.baseline_metrics_['r2']:.4f}\")",
        "",
        "# View number of selected models",
        "print(f\"\\nNumber of models selected for ensemble: {len(regressor_elastic.selected_models_)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate predictions",
        "y_pred_elastic = regressor_elastic.predict(X_test)",
        "",
        "# Calculate performance metrics",
        "from sklearn.metrics import r2_score, mean_absolute_error",
        "",
        "r2_elastic = r2_score(y_test, y_pred_elastic)",
        "mae_elastic = mean_absolute_error(y_test, y_pred_elastic)",
        "",
        "print(\"\\n=== ElasticNet Ensemble Performance ===\")",
        "print(f\"R² Score: {r2_elastic:.4f}\")",
        "print(f\"Mean Absolute Error: {mae_elastic:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 2: MARS Ensemble Method",
        "",
        "Now let's train an Paramsemble model using the MARS (Multivariate Adaptive Regression Splines) ensemble method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize Paramsemble with MARS ensembleregressor_mars = ParamsembleRegressor(    m=50,    f=5,    sample='unique',    method='mars',           # Use MARS for ensemble    spread=10,    ELM2json='models/constituent_models_mars.json',    modeljson='models/ensemble_model_mars.json',    random_state=42)print(\"Training Paramsemble with MARS ensemble...\")regressor_mars.fit(X_train, y_train, X_test, y_test)print(\"Training complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate predictions",
        "y_pred_mars = regressor_mars.predict(X_test)",
        "",
        "# Calculate performance metrics",
        "r2_mars = r2_score(y_test, y_pred_mars)",
        "mae_mars = mean_absolute_error(y_test, y_pred_mars)",
        "",
        "print(\"\\n=== MARS Ensemble Performance ===\")",
        "print(f\"R² Score: {r2_mars:.4f}\")",
        "print(f\"Mean Absolute Error: {mae_mars:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Serialization and Scoring Workflow\n",
        "\n",
        "Demonstrate how to save models and use them for scoring new data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate new scoring data\n",
        "X_new, _ = make_regression(\n",
        "    n_samples=100,\n",
        "    n_features=15,\n",
        "    n_informative=10,\n",
        "    noise=10.0,\n",
        "    random_state=123\n",
        ")\n",
        "X_new_df = pd.DataFrame(X_new, columns=feature_names)\n",
        "X_new_df['id'] = range(1, 101)\n",
        "\n",
        "print(f\"New scoring dataset: {X_new_df.shape[0]} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Score using saved ElasticNet model",
        "predictions_elastic = regressor_elastic.score_from_json(",
        "    X_new_df.drop('id', axis=1),",
        "    'models/ensemble_model_elastic.json',",
        "    id_column=X_new_df['id']",
        ")",
        "",
        "print(\"\\n=== Predictions from Saved ElasticNet Model ===\")",
        "print(predictions_elastic.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Score using saved MARS model",
        "predictions_mars = regressor_mars.score_from_json(",
        "    X_new_df.drop('id', axis=1),",
        "    'models/ensemble_model_mars.json',",
        "    id_column=X_new_df['id']",
        ")",
        "",
        "print(\"\\n=== Predictions from Saved MARS Model ===\")",
        "print(predictions_mars.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SQL Export for Database Deployment\n",
        "\n",
        "Export the trained model as SQL code for deployment in database environments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export ElasticNet model to SQL",
        "sql_code_elastic = regressor_elastic.export_sql(",
        "    'models/ensemble_model_elastic.json',",
        "    table_name='input_features',",
        "    id_column='sample_id'",
        ")",
        "",
        "print(\"\\n=== SQL Export (ElasticNet Model) ===\")",
        "print(\"\\nFirst 1500 characters of generated SQL:\")",
        "print(sql_code_elastic[:1500])",
        "print(\"\\n... (truncated)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save SQL to file\n",
        "with open('models/ensemble_model_elastic.sql', 'w') as f:\n",
        "    f.write(sql_code_elastic)\n",
        "\n",
        "print(\"SQL code saved to: models/ensemble_model_elastic.sql\")\n",
        "print(\"\\nYou can now execute this SQL in your database:\")\n",
        "print(\"  - PostgreSQL: psql -d your_database -f ensemble_model_elastic.sql\")\n",
        "print(\"  - MySQL: mysql -u user -p database < ensemble_model_elastic.sql\")\n",
        "print(\"  - SQL Server: sqlcmd -S server -d database -i ensemble_model_elastic.sql\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Performance Visualization and Comparison\n",
        "\n",
        "Visualize and compare the performance of different models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comparison plot\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Plot 1: Actual vs Predicted (ElasticNet)\n",
        "axes[0].scatter(y_test, y_pred_elastic, alpha=0.5, s=30)\n",
        "axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
        "axes[0].set_xlabel('Actual Values', fontsize=12)\n",
        "axes[0].set_ylabel('Predicted Values', fontsize=12)\n",
        "axes[0].set_title(f'ElasticNet Ensemble\\nR² = {r2_elastic:.4f}, MAE = {mae_elastic:.2f}', fontsize=14)\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Actual vs Predicted (MARS)\n",
        "axes[1].scatter(y_test, y_pred_mars, alpha=0.5, s=30, color='green')\n",
        "axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
        "axes[1].set_xlabel('Actual Values', fontsize=12)\n",
        "axes[1].set_ylabel('Predicted Values', fontsize=12)\n",
        "axes[1].set_title(f'MARS Ensemble\\nR² = {r2_mars:.4f}, MAE = {mae_mars:.2f}', fontsize=14)\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Residual plots\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# ElasticNet residuals\n",
        "residuals_elastic = y_test - y_pred_elastic\n",
        "axes[0].scatter(y_pred_elastic, residuals_elastic, alpha=0.5, s=30)\n",
        "axes[0].axhline(y=0, color='r', linestyle='--', lw=2)\n",
        "axes[0].set_xlabel('Predicted Values', fontsize=12)\n",
        "axes[0].set_ylabel('Residuals', fontsize=12)\n",
        "axes[0].set_title('ElasticNet Ensemble - Residual Plot', fontsize=14)\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# MARS residuals\n",
        "residuals_mars = y_test - y_pred_mars\n",
        "axes[1].scatter(y_pred_mars, residuals_mars, alpha=0.5, s=30, color='green')\n",
        "axes[1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
        "axes[1].set_xlabel('Predicted Values', fontsize=12)\n",
        "axes[1].set_ylabel('Residuals', fontsize=12)\n",
        "axes[1].set_title('MARS Ensemble - Residual Plot', fontsize=14)\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model comparison bar chart",
        "models = ['Baseline\\n(Random Forest)', 'ElasticNet\\nEnsemble', 'MARS\\nEnsemble']",
        "r2_scores = [",
        "    regressor_elastic.baseline_metrics_['r2'],",
        "    r2_elastic,",
        "    r2_mars",
        "]",
        "",
        "fig, ax = plt.subplots(figsize=(10, 6))",
        "bars = ax.bar(models, r2_scores, color=['#1f77b4', '#ff7f0e', '#2ca02c'], alpha=0.7)",
        "ax.set_ylabel('R² Score', fontsize=12)",
        "ax.set_title('Model Performance Comparison', fontsize=14, fontweight='bold')",
        "ax.set_ylim([min(r2_scores) * 0.95, max(r2_scores) * 1.05])",
        "ax.grid(True, alpha=0.3, axis='y')",
        "",
        "# Add value labels on bars",
        "for bar, score in zip(bars, r2_scores):",
        "    height = bar.get_height()",
        "    ax.text(bar.get_x() + bar.get_width()/2., height,",
        "            f'{score:.4f}',",
        "            ha='center', va='bottom', fontsize=11, fontweight='bold')",
        "",
        "plt.tight_layout()",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Constituent model performance distribution",
        "constituent_r2_scores = [model['r2'] for model in regressor_elastic.constituent_models_]",
        "selected_r2_scores = [model['r2'] for model in regressor_elastic.selected_models_]",
        "",
        "fig, ax = plt.subplots(figsize=(12, 6))",
        "ax.hist(constituent_r2_scores, bins=20, alpha=0.6, label='All Constituent Models', color='blue')",
        "ax.hist(selected_r2_scores, bins=10, alpha=0.8, label='Selected for Ensemble', color='orange')",
        "ax.axvline(regressor_elastic.baseline_metrics_['r2'], color='red', linestyle='--', ",
        "           linewidth=2, label='Baseline R²')",
        "ax.set_xlabel('R² Score', fontsize=12)",
        "ax.set_ylabel('Frequency', fontsize=12)",
        "ax.set_title('Distribution of Constituent Model Performance', fontsize=14, fontweight='bold')",
        "ax.legend(fontsize=11)",
        "ax.grid(True, alpha=0.3)",
        "",
        "plt.tight_layout()",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create summary table",
        "summary_data = {",
        "    'Model': ['Baseline (Random Forest)', 'ElasticNet Ensemble', 'MARS Ensemble'],",
        "    'R² Score': [",
        "        regressor_elastic.baseline_metrics_['r2'],",
        "        r2_elastic,",
        "        r2_mars",
        "    ],",
        "    'MAE': [",
        "        'N/A',",
        "        f\"{mae_elastic:.4f}\",",
        "        f\"{mae_mars:.4f}\"",
        "    ],",
        "    'wMAPE': [",
        "        f\"{regressor_elastic.baseline_metrics_['wmape']:.4f}\",",
        "        'N/A',",
        "        'N/A'",
        "    ]",
        "}",
        "",
        "summary_df = pd.DataFrame(summary_data)",
        "print(\"\\n=== Model Performance Summary ===\")",
        "print(summary_df.to_string(index=False))",
        "",
        "print(f\"\\n\\nTotal constituent models trained: {len(regressor_elastic.constituent_models_)}\")",
        "print(f\"Models selected for ensemble: {len(regressor_elastic.selected_models_)}\")",
        "print(f\"Feature combinations per model: {regressor_elastic.f}\")",
        "print(f\"Total features available: {X_train.shape[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ConclusionThis notebook demonstrated:1. **Training Paramsemble models** with both ElasticNet and MARS ensemble methods2. **Model serialization** - saving models to JSON for later use3. **Scoring workflow** - loading saved models and generating predictions on new data4. **SQL export** - converting trained models to executable SQL for database deployment5. **Performance visualization** - comparing model performance with various plots### Key Takeaways:- Paramsemble automatically generates and evaluates multiple feature combinations- The ensemble approach combines the best-performing constituent models- Both ElasticNet and MARS methods can capture different patterns in the data- Models can be easily serialized and deployed in production environments- SQL export enables database-native predictions without Python dependencies### Next Steps:- Experiment with different hyperparameters (m, f, spread)- Try different sampling methods ('unique' vs 'replace')- Apply Paramsemble to your own regression problems- Deploy SQL models in your database environment"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}